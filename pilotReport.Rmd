---
title: "CARPS Reproducibility Report"
output:
  html_document:
    toc: true
    toc_float: true
---
# Report Details

```{r}
articleID <- "CARPS_EXT_18-6-2015" # insert the article ID code here e.g., "10-3-2015_PS"
reportType <- "pilot" # specify whether this is the 'pilot' report or 'final' report
pilotNames <- "Lindsey Hasak" # insert the pilot's name here e.g., "Tom Hardwicke".  If there are multiple cpilots enter both names in a character string e.g., "Tom Hardwicke, Bob Dylan"
copilotNames <- NA  # insert the co-pilot's name here e.g., "Michael Frank". If there are multiple co-pilots enter both names in a character string e.g., "Tom Hardwicke, Bob Dylan"
pilotTTC <- 120 # insert the pilot's estimated time to complete (in minutes, fine to approximate) e.g., 120
copilotTTC <- NA # insert the co-pilot's estimated time to complete (in minutes, fine to approximate) e.g., 120
pilotStartDate <- as.Date("11/03/2018") # insert the pilot's start date in US format e.g., as.Date("01/25/18", format = "%m/%d/%y")
copilotStartDate <- NA # insert the co-pilot's start date in US format e.g., as.Date("01/25/18", format = "%m/%d/%y")
completionDate <- as.Date("11/09/2018") # copilot insert the date of final report completion (after any necessary rounds of author assistance) in US format e.g., as.Date("01/25/18", format = "%m/%d/%y")
```

------

#### Methods summary: 

The authors recruited a sample of 2,898 participants through Amazon Mechanical Turk (MTurk from here forward). Subjects were recruited through 50 separate surveys hosted on MTurk, with each survey aimed at recruiting participants from each of the U.S. states. The critical question was about state narcissism, or what percentage a participant believed their home state contributed to the historical developments of the United States, considering that the contributions of 50 states should sum to 100%. To complete the study, MTurk participants answered a survey through Qualtrix that randomly assigned them into a prime or no-prime condition. Participants in both conditions completed a demographics questionnaire before moving on to the study. In the prime condition, participants were asked to generate the ten most important events in US history and answer 15 questions about US history before answering the critical question. Participants in the no-prime condition followed the opposite procedure: answering the critical question, and then generating historical events and answering history questions. Afterward, subjects were asked to rate the contribution of 10 random states (excluding their home state) to US history, select the three states that they believed contributed most to US history, and then identify which state they believed contributed least to US history, and which state is most influential in present-day. As the final task, participants completed a variation of the critical question by assigning US history contribution percentages to their home state, the three states that they had selected as being the largest contributors, and all other states after being reminded that the total contribution for all categories had to equal 100 percent.In addition to failing to respond to the critical question about state narcissism (n = 5) and taking the survey more than once (n = 19), the researchers excluded participants for the following reasons:

> not following instructions for reporting events on a U.S. history quiz (n = 238); answering fewer than 5 questions correctly on the 15-question history quiz (n = 132); self-reports indicating that they had not spent at least 5 years in their home state (n = 93); did not speak English fluently (n = 27); had consulted outside sources on the history quiz (n = 57); Putnam et al., p.1415.

------

#### Target outcomes: 

For this article you should focus on the findings reported in the results section pertaining to "Resident and nonresident estimates of state contributions to U.S. history".

Specifically, you should attempt to reproduce all descriptive and inferential analyses reported in the text below and associated tables/figures:

> Resident and nonresident estimates of
state contributions to U.S. history.
The average estimated contribution for residents from
all states was 18.25%, 95% CI = [17.53%, 18.97%]. Summing
the average contribution from all states (which
logically should equal 100%) yielded an astounding
907%, indicating a strong bias to overclaim responsibility.
The estimates from different states also ranged
widely. Figure 1 provides a heat map showing the estimated
resident contribution for each state (more details
are available in Table S1 in the Supplemental Material).
Iowans gave the lowest rating at 9%, whereas Virginians
gave the highest rating at 41%, indicating that states
showed highly variable estimates of responsibility. Of
course, Virginians have contributed more to American
history than Iowans, but these judged percentages are
still quite high. The editor of this journal referred to
such high numbers as “ludicrous,” and he has a point—
Virginians and Iowans together were not responsible
for 50% of U.S. history. Still, these consistently high
numbers came from people in all 50 states.
Of course, there was also variability within a state
in how people responded. Figure 2 shows the aggregate
histogram of data from all 50 states, revealing a strong
positive skew. Although most estimates (72%) were
below or equal to 20%, there were a number of much
higher responses, particularly in eastern states (e.g.,
Virginia, Delaware, and Massachusetts), indicating that
some people thought that their home states had made
hugely significant contributions to U.S. history.

------

```{r global_options, include=FALSE}
# sets up some formatting options for the R Markdown document
knitr::opts_chunk$set(echo=TRUE, warning=FALSE, message=FALSE)
```

# Step 1: Load packages and prepare report object

```{r}
# load packages
library(tidyverse) # for data munging
library(knitr) # for kable table formating
library(haven) # import and export 'SPSS', 'Stata' and 'SAS' Files
library(readxl) # import excel files
library(CARPSreports) # custom report functions
library(agrmt)
library(pastecs)
library(maps)
library(usmap)#added to create heat map
```

```{r}
# Prepare report object. This will be updated automatically by the reproCheck function each time values are compared
reportObject <- data.frame(dummyRow = TRUE, reportedValue = NA, obtainedValue = NA, valueType = NA, percentageError = NA, comparisonOutcome = NA, eyeballCheck = NA)
```

# Step 2: Load data

```{r}
#Create list of state names
stateList = c("Alabama", "Alaska", "Arizona", "Arkansas", "California", "Colorado", "Connecticut", "Delaware", "Florida", "Georgia", "Hawaii", "Idaho", "Illinois", "Indiana", "Iowa", "Kansas", "Kentucky", "Louisiana", "Maine", "Maryland", "Massachusetts", "Michigan", "Minnesota", "Mississippi", "Missouri", "Montana", "Nebraska", "Nevada", "New Hampshire", "New Jersey", "New Mexico", "New York", "North Carolina", "North Dakota", "Ohio", "Oklahoma", "Oregon", "Pennsylvania", "Rhose Island", "South Carolina", "South Dakota", "Tennessee", "Texas", "Utah", "Vermont", "Virgina", "Washington", "West Virginia", "Wisconsin", "Wyoming")
stateList

#Import raw data (Formatted as shown in the State Narcissism Data Scrub.R file)
noHeaders = read.csv("data/State Narcissism Raw Data.csv", header = F, skip = 3) # import data without headers 
headers = read.csv("data/State Narcissism Raw Data.csv", header = F, colClasses = "character") # import the data for header rows
headers = headers[1:3,  ] # omit non-header rows
names(noHeaders) = iconv(headers[2,  ], "latin1", "ASCII", sub = "") # pull row 2 and remove multi-byte characters; save as headers
state.data = noHeaders # start main DF
state.data[state.data == ""] = NA # convert blank cells to NA

```


# Step 3: Tidy data

Below is a quick attempt to tidy the raw data for this Reproducibility report. Although I originally intended to filter the data from scratch on my own, I realized that, at my current skill level, I was unable to do so without following the author's exact method, which I have included in the "Step 2 Repeat" and "Step 3 Repeat" sections.


```{r}
#Delete unecessary columns for reproducibility report analysis
filtered.state.data <- state.data %>% 
  select(-"ResponseID",
         -"ResponseSet",
         -"ExternalDataReference",
         -"Finished",
         -"Status",
         -"Score-weightedAvg",
         -"Score-weightedStdDev",
         -starts_with("Recipient"),
         -starts_with("Welcome!"),
         -starts_with("IMPORTANT"),
         -starts_with("Please answer"),
         -"StartDate",
         -"EndDate",
         -starts_with("Do you agree"),
         -"Score-sum")

colnames(filtered.state.data)[38] = "historyScore"
colnames(filtered.state.data)
sum(filtered.state.data$historyScore)
```

# Step 4: Run analysis

# Step 2 Repeat: Load Scrubbed Data from OSF

The data cleaning process was intense, and I could not reproduce it without following the authors' original code explicitly. To obtain the most accurate reproduction, I will run analyses using the included "State Narcissism Data Scrub.R" file, as shown below.

```{r}
# * * * * * * * * LOAD PACKAGES * * * * * * * * 
library(reshape)
library(plyr)
library(psych)

# * * * * * * * * IMPORT DATA AND LIST OF STATES * * * * * * * * 
# pull in list of states
stateList = c("Alabama", "Alaska", "Arizona", "Arkansas", "California", "Colorado", "Connecticut", "Delaware", 
       "Florida", "Georgia", "Hawaii", "Idaho", "Illinois", "Indiana", "Iowa", "Kansas", "Kentucky", 
       "Louisiana", "Maine", "Maryland", "Massachusetts", "Michigan", "Minnesota", "Mississippi", 
       "Missouri", "Montana", "Nebraska", "Nevada", "New Hampshire", "New Jersey", "New Mexico", 
       "New York", "North Carolina", "North Dakota", "Ohio", "Oklahoma", "Oregon", "Pennsylvania", 
       "Rhode Island", "South Carolina", "South Dakota", "Tennessee", "Texas", "Utah", "Vermont", 
       "Virginia", "Washington", "West Virginia", "Wisconsin", "Wyoming") 

# import data
noHeaders = read.csv("data/State Narcissism Raw Data.csv", header = F, skip = 3) # import data without headers 
headers = read.csv("data/State Narcissism Raw Data.csv", header = F, colClasses = "character") # import the data for header rows
headers = headers[1:3,  ] # omit non-header rows
names(noHeaders) = iconv(headers[2,  ], "latin1", "ASCII", sub = "") # pull row 2 and remove multi-byte characters; save as headers
data = noHeaders # start main DF
data[data == ""] = NA # convert blank cells to NA
```

# Step 3 Repeat: Tidy Data

Below are the authors' original steps to clean and tidy their data. I will use the files generated from this process to complete the analyses in Step 4, and reproduce figures in Step 5.

```{r}

# * * * * * * * * CLEAN UP DATA SET (DELETE UNUSED COLUMNS AND RENAME OTHERS) * * * * * * * *
# build an array with column names to delete
columnsToDelete = c("ResponseID",  "ResponseSet",  "ExternalDataReference",  "Finished",  "Status", "Score-weightedAvg", "Score-weightedStdDev")
columnsToDelete = append(columnsToDelete, grep("Recipient", names(data), value = TRUE))
columnsToDelete = append(columnsToDelete, grep("Thank", names(data), value = TRUE))
columnsToDelete = append(columnsToDelete, grep("Welcome!", names(data), value = TRUE))
columnsToDelete = append(columnsToDelete, grep("IMPORTANT", names(data), value = TRUE, ignore.case = TRUE))
columnsToDelete = append(columnsToDelete, grep("Please answer", names(data), value = TRUE))
columnsToDelete = append(columnsToDelete, grep("You will now be", names(data), value = TRUE))

columnsToDelete2 = names(data) %in% columnsToDelete # create TF vector based on the names

# then exclude the columns from the above array, so that we are left with only the columns we want
trimmedData = data[!columnsToDelete2]

# Rename column names
colnames(trimmedData)[3] = "historyScore"
colnames(trimmedData)[5] = "consent"
colnames(trimmedData)[8] = "citizenship"
colnames(trimmedData)[9] = "education"
colnames(trimmedData)[10] = "fluentEnglish"
colnames(trimmedData)[11] = "birthState"
colnames(trimmedData)[12] = "homeState"
colnames(trimmedData)[13] = "homeState.Years"
colnames(trimmedData)[14] = "currentState"
colnames(trimmedData)[15:24] = paste("Important Event", as.character(1:10))
colnames(trimmedData)[40] = "criticalQuestion"
colnames(trimmedData)[41:90] = paste(as.character(stateList), " NR Rating")
colnames(trimmedData)[91] = "contributedMostState"
colnames(trimmedData)[92] = "contributed2ndMostState"
colnames(trimmedData)[93] = "contributed3rdMostState"
colnames(trimmedData)[94] = "contMostStateRating"
colnames(trimmedData)[95] = "cont2ndMostStateRating"
colnames(trimmedData)[96] = "cont3rdMostStateRating"
colnames(trimmedData)[97] = "contributedLeastMost"
colnames(trimmedData)[98] = "mostSway"
colnames(trimmedData)[99] = "homeState100Percent"
colnames(trimmedData)[100] = "most100Percent"
colnames(trimmedData)[101] = "2ndMost100Percent"
colnames(trimmedData)[102] = "3rdMost100Percent"
colnames(trimmedData)[103] = "allOther100Percent"
colnames(trimmedData)[104] = "egocentricPrediction"
colnames(trimmedData)[105] = "Plus 5 - No State"
colnames(trimmedData)[106:152] = paste("Plus 5 - ", as.character(stateList[1:47]))
colnames(trimmedData)[153] = "Plus 5 - Washington D.C."
colnames(trimmedData)[154:156] = paste("Plus 5 - ", as.character(stateList[48:50]))
colnames(trimmedData)[157] = "Cheat"
colnames(trimmedData)[158] = "Look up?"
colnames(trimmedData)[159] = "surveyDifficulty"
colnames(trimmedData)[160] = "generalComments"

# add subject number and determine sample size
trimmedData$subjectNumber = 1:nrow(trimmedData)
n = max(trimmedData$subjectNumber)
n

# * * * * * * * * CUT DATA BASED ON A PRIORI CRITERIA * * * * * * * 
# check for cuts based on manual inspection of 10 critical events (+ subjects who had duplicate MTurk IDs)
cutListDF = read.csv("data/historyCuts.csv", header = T) # read in the list of subject numbers to cut from manual inspection.

cutList = cutListDF$subNum # list of subjects to cut

 # start a DF to store data that we are cutting
 cutData = trimmedData[cutList, ] 
 tenEventDrops = nrow(cutData) # calculate # of subjects cut from 10 events failures & mturk ID duplicates
 
 # save the data that we want
 trimmedDataTen = trimmedData[-cutList, ] 

# cut subjects based low history score, cheating, not living in state for at least five years,  not speaking english, or if there is an NA for the critical question
trimmedDataHistory = trimmedDataTen[trimmedDataTen$historyScore > 4, ] 
trimmedDataNoCheat = trimmedDataHistory[trimmedDataHistory$Cheat == "No", ]
trimmedDataPlusFive = trimmedDataNoCheat[trimmedDataNoCheat$homeState.Years != "1 to 5", ]
trimmedDataEnglish = trimmedDataPlusFive[trimmedDataPlusFive$fluentEnglish == "Yes", ]
trimmedDataOMiss = trimmedDataEnglish[!is.na(trimmedDataEnglish$criticalQuestion), ] # use is.na() to pull a TF vector for critical question being NA. Grab opposite.

 # save the cut data for each criteria to the cutData dataframe
 cutData = rbind(cutData, trimmedDataTen[trimmedDataTen$historyScore < 5, ]) # X
 cutData = rbind(cutData, trimmedDataHistory[trimmedDataHistory$Cheat == "Yes", ]) 
 cutData = rbind(cutData, trimmedDataNoCheat[trimmedDataNoCheat$homeState.Years == "1 to 5", ])
 cutData = rbind(cutData, trimmedDataPlusFive[trimmedDataPlusFive$fluentEnglish == "No", ])
 cutData = rbind(cutData, trimmedDataEnglish[is.na(trimmedDataEnglish$criticalQuestion), ])

# save final data
finalData = trimmedDataOMiss

# renumber subject numbers & count subjects
finalData$subjectNumber = 1:nrow(finalData)
finalN = nrow(finalData)
finalN

# check to see the count for each state (before and after cuts)
table(trimmedData$homeState)
table(finalData$homeState)

# calculate the number of dropped subjects for each ommission criteria
historyDrops = nrow(trimmedDataTen) - nrow(trimmedDataHistory)
cheatDrops = nrow(trimmedDataHistory) - nrow(trimmedDataNoCheat)
shortStayDrops = nrow(trimmedDataNoCheat) - nrow(trimmedDataPlusFive)
nonfluentEnglishDrops = nrow(trimmedDataPlusFive) - nrow(trimmedDataEnglish)
missingCQDataDrops = nrow(trimmedDataEnglish) - nrow(trimmedDataOMiss)

# report # of drops for each criteria
tenEventDrops - 19 # 19 duplicate mturk ids included in the ten events drop 
historyDrops
cheatDrops
shortStayDrops
nonfluentEnglishDrops
missingCQDataDrops

# * * * * * * * * GENERATE A SUBJECT LEVEL SUMMARY * * * * * * * *
subjectData = finalData[ , c(1:24, 40, 91:104, 157:161)] # grab everything but history quiz responses, random state ratings, +5 years, MTurkID

# add each subject's average rating for random state
subjectData$Random.State.Ratings = rowMeans(finalData[, 41:90], na.rm = T)

# save Subject Level Data to a text file 
write.csv(subjectData, file = "data/subjectLevelData.csv")

# OPTIONAL save cut data
 # write.csv(cutData, file = "cutData.csv")

# * * * * * * * * STATE LEVEL SUMMARY * * * * * * * *

# calculate the average non-resident rating for each state
rStateMean = colMeans(finalData[, 41:90], na.rm = TRUE)
rStateSD = apply(finalData[, 41:90], 2, sd, na.rm = TRUE)

# combine the random state ratings w/their names (and add labels)
stateData = data.frame(as.character(stateList), rStateMean, rStateSD)
colnames(stateData) = c("state", "NR.State.Mean", "NR.State.SD")
rownames(stateData) = as.character(stateList)

# add the resident ratings to the state data summary
stateData$Rrating = tapply(finalData$criticalQuestion, finalData$homeState, mean)
stateData$RratingSD = tapply(finalData$criticalQuestion, finalData$homeState, sd)

# reorder columns to put resident ratings first.
stateData = stateData[, c(1, 4, 5, 2, 3)]

# add the resident rating split by condition (P and NP) 
# first create two new DFs based on the prime condition
primeData = subset(finalData, Condition == "P")
noPrimeData = subset(finalData, Condition == "NP")

# then calculate means for the resident states
stateData$Prime.Rrating = tapply(primeData$criticalQuestion, primeData$homeState, mean)
stateData$Prime.RratingSD = tapply(primeData$criticalQuestion, primeData$homeState, sd)
stateData$NoPrime.Rrating = tapply(noPrimeData$criticalQuestion, noPrimeData$homeState, mean)
stateData$NoPrime.RratingSD = tapply(noPrimeData$criticalQuestion, noPrimeData$homeState, sd)

# calculate means for 100% restriction version of question
 # first replace any NAs with 0 for homeState 100 and ContributedMost 100 [subjects may have left field blank]
 finalData$homeState100Percent[is.na(finalData$homeState100Percent)] = 0
 finalData$most100Percent[is.na(finalData$most100Percent)] = 0 
 finalData$`2ndMost100Percent`[is.na(finalData$`2ndMost100Percent`)] = 0 
 finalData$`3rdMost100Percent`[is.na(finalData$`3rdMost100Percent`)] = 0 

  # save results to state data frame 
  stateData$State100PercentMean.ALL = tapply(finalData$homeState100Percent, finalData$homeState, mean, na.rm = T)
  stateData$State100PercentSD.ALL = tapply(finalData$homeState100Percent, finalData$homeState, sd, na.rm = T)

# add the 100% question to the state dataframe but cutting where subjects did not follow directions (e.g., they listed
  # their home state as one of the most important states and rated it twice in the question.
    sd100.1 = subset(finalData, as.character(homeState) != as.character(contributedMostState))
    sd100.2 = subset(sd100.1, as.character(homeState) != as.character(contributed2ndMostState))
    sd100.3 = subset(sd100.2, as.character(homeState) != as.character(contributed3rdMostState))
 
  # calculate the 100% homeState question for each state and save to the state dataframe
    stateData$State100PercentMean = tapply(sd100.3$homeState100Percent, sd100.3$homeState, mean, na.rm = T)
    stateData$State100PercentSD = tapply(sd100.3$homeState100Percent, sd100.3$homeState, sd, na.rm = T)
 
# add 100% version of question, but only cut subjects who failed to follow directions (they not only listed homestate twice,
  # but rated it twice as well)  

  oneHundredData = finalData[ , c(12, 91, 92, 93, 99:103, 161)] # grab just relevant info
  
  oneHundred1Double = subset(oneHundredData, as.character(oneHundredData$homeState) == as.character(oneHundredData$contributedMostState)) 
  oneHundred2Double = subset(oneHundredData, as.character(oneHundredData$homeState) == as.character(oneHundredData$contributed2ndMostState))
  oneHundred3Double = subset(oneHundredData, as.character(oneHundredData$homeState) == as.character(oneHundredData$contributed3rdMostState))
  
  # pull and calculate the number of subjects who did not follow directions for Most Important
  oneHundred1DoubleFollow = subset(oneHundred1Double, oneHundred1Double$homeState100Percent == 0 | oneHundred1Double$most100Percent == 0)
  nrow(oneHundred1Double) # how many people listed home state as most important
  nrow(oneHundred1DoubleFollow) # how many people " and followed directions
  mostFail = nrow(oneHundred1Double) - nrow(oneHundred1DoubleFollow) # how many people " and did NOT follow directions
  
  # pull and calculate the number of subjects who did not follow directions for 2nd Most Important
  oneHundred2DoubleFollow = subset(oneHundred2Double, oneHundred2Double$homeState100Percent == 0 | oneHundred2Double$`2ndMost100Percent` == 0)
  nrow(oneHundred2Double) # how many people listed home state as 2nd most important
  nrow(oneHundred2DoubleFollow) # how many people " and followed directions
  mostFail2 = nrow(oneHundred2Double) - nrow(oneHundred2DoubleFollow) # how many people " and did NOT follow directions
  mostFail2
  
  # pull and calculate the number of subjects who did not follow directions for 3rd Most Important
  oneHundred3DoubleFollow = subset(oneHundred3Double, oneHundred3Double$homeState100Percent == 0 | oneHundred3Double$`3rdMost100Percent` == 0)
  nrow(oneHundred3Double) # how many people listed home state as 2nd most important
  nrow(oneHundred3DoubleFollow) # how many people " and followed directions
  mostFail3 = nrow(oneHundred3Double) - nrow(oneHundred3DoubleFollow) # how many people " and did NOT follow directions
  mostFail3
  
  # identify subjects who failed to follow instructions
  fail1 = subset(oneHundred1Double, oneHundred1Double$homeState100Percent != 0 & oneHundred1Double$most100Percent != 0)
  fail2 = subset(oneHundred2Double, oneHundred2Double$homeState100Percent != 0 & oneHundred2Double$`2ndMost100Percent` != 0)
  fail3 = subset(oneHundred3Double, oneHundred3Double$homeState100Percent != 0 & oneHundred3Double$`3rdMost100Percent` != 0)
  
  failSubjectList = c(fail1$subjectNumber, fail2$subjectNumber, fail3$subjectNumber)
  table(failSubjectList) # note that subjects 310 and 2835 rated their homestate 3 times! so they are counted twice here
  length(unique(failSubjectList)) # how many subjects did not follow instructions
  
  # exclude all of the subjects who failed to follow instructions 
  cut100Data = finalData[-failSubjectList, ]
  
  stateData$noFail100Mean = tapply(cut100Data$homeState100Percent, cut100Data$homeState, mean)
  stateData$noFail100SD = tapply(cut100Data$homeState100Percent, cut100Data$homeState, sd)

  
## * * * * * * * * * * * * * * * * * * * * * * * *     
  
# calculate the narcissistic index for each state
stateData$Narc.Index = stateData$Rrating - stateData$NR.State.Mean
 
# tally the number of residents who rated a state
stateData$RCount = tapply(finalData$homeState, finalData$homeState, length)
 
# tally the number of non-residents who rated a state
stateData$NRCount = apply(finalData[, 41:90], 2, function(x) length(which(!is.na(x))))
 
# count the n for each state reported in 100% version of the question when we eliminated the subjects who rated 
#their home state in the top 3 (including them would be same as resident rating).
stateData$State100PercentCount = tapply(sd100.3$homeState, sd100.3$homeState, length)

# * * * * * * * * SAVE STATE LEVEL SUMMARY AND FINAL DATA* * * * * * * * 
write.csv(stateData, "stateLevelData.csv")
write.csv(finalData, "State Narcissism Scrubbed Data.csv")
```


## Descriptive statistics

```{r}
#Resident and nonresident estimates of state contributions to U.S. history.
#Avg Resident Estimate
meanCQ <- mean(finalData$criticalQuestion)
meanCQ 

reportObject <- reproCheck(reportedValue = '18.25', obtainedValue = meanCQ, valueType = 'mean') #Check for match

#95% Confidence Interval Limits
summaryCQ <- stat.desc(finalData$criticalQuestion)

upper.limit <- meanCQ + summaryCQ[[11]]
upper.limit 

reportObject <- reproCheck(reportedValue = '18.97', obtainedValue = upper.limit, valueType = 'ci') #Check for match

lower.limit <- meanCQ - summaryCQ[[11]]
lower.limit 

reportObject <- reproCheck(reportedValue = '17.53', obtainedValue = lower.limit, valueType = 'ci') #Check for match

#Sum of average state estimates
sumCQ <- sum(stateData$Rrating)
sumCQ 

reportObject <- reproCheck(reportedValue = '907', obtainedValue = sumCQ, valueType = 'other') #Check for match


#Lowest rated contribution
 min.state <- row.names(stateData)[(which(stateData$Rrating==min(stateData$Rrating)))]
 min.state
 
#Highest rated contribution
 max.state <- row.names(stateData)[(which(stateData$Rrating==max(stateData$Rrating)))]
 max.state 

```

#Figure Reproduction

```{r}
#Heat Map
state.map <- plot_usmap(data = stateData, values = "Rrating", lines = "white") + 
  scale_fill_continuous(name = "Resident Rating", low = "pink", high = "darkred", guide = "colorbar") + 
  labs(title = "Resident Ratings by State", guide = "Resident Rating") +
  theme(legend.position = "bottom")

state.map #without rating labels on top of state, but the similarity of the colors for each state allows me to conclude that the heat map is reproducible

#Histogram

state.hist <- ggplot(finalData, aes(x = criticalQuestion)) + 
  geom_histogram(binwidth = 5, boundary = 0, fill = "white", color = "black") +
  labs(title = "Distribution of Responses to Critical Question (All States)") + 
  scale_x_continuous(name = "Percentage Estimate of State's Contribution",
                     breaks = seq(0, 100, 10),
                     limits = c(0, 100)) +
  scale_y_continuous(name = "Number of Responses",
                     breaks = seq(0, 1000, 200),
                     limits = c(0, 1000)) + 
  theme_bw()
state.hist
```

## Inferential statistics

No inferential statistics were included in the part of the text that this Reproducibility Report was responsible for.

# Step 5: Conclusion

The reproducibility check for the target outcomes of this report was a success. All descriptive statistics were matches, except for the confidence interval for estimations of state contributions, which resulted in a minor numerical error of 0.06%. However, this difference does not affect the conclusions of the study.  Additionally, I was successfully able to reproduce Figure 2, the histogram, and partially able to reproduce Figure 1, the heat map. The package that the authors used to produce the heat map (fiftystater) is no longer available, and I was unable to figure out how to add rating labels on top of each state with the package I used instead (plot_usmap). Due to the similar color scheme for each state between my graph and the original, I conclude that Figure 1 is also reproducible, and attribute the lack of labels to my own ability rather than a reproducibility error of the original authors.


```{r}
Author_Assistance = FALSE # was author assistance provided? (if so, enter TRUE)

Insufficient_Information_Errors <- 0 # how many discrete insufficient information issues did you encounter?

# Assess the causal locus (discrete reproducibility issues) of any reproducibility errors. Note that there doesn't necessarily have to be a one-to-one correspondance between discrete reproducibility issues and reproducibility errors. For example, it could be that the original article neglects to mention that a Greenhouse-Geisser correct was applied to ANOVA outcomes. This might result in multiple reproducibility errors, but there is a single causal locus (discrete reproducibility issue).

locus_typo <- 0 # how many discrete issues did you encounter that related to typographical errors?
locus_specification <- 0 # how many discrete issues did you encounter that related to incomplete, incorrect, or unclear specification of the original analyses?
locus_analysis <- 0 # how many discrete issues did you encounter that related to errors in the authors' original analyses?
locus_data <- 0 # how many discrete issues did you encounter that related to errors in the data files shared by the authors?
locus_unidentified <- 0 # how many discrete issues were there for which you could not identify the cause

# How many of the above issues were resolved through author assistance?
locus_typo_resolved <- NA # how many discrete issues did you encounter that related to typographical errors?
locus_specification_resolved <- NA # how many discrete issues did you encounter that related to incomplete, incorrect, or unclear specification of the original analyses?
locus_analysis_resolved <- NA # how many discrete issues did you encounter that related to errors in the authors' original analyses?
locus_data_resolved <- NA # how many discrete issues did you encounter that related to errors in the data files shared by the authors?
locus_unidentified_resolved <- NA # how many discrete issues were there for which you could not identify the cause

Affects_Conclusion <- FALSE # Do any reproducibility issues encounter appear to affect the conclusions made in the original article? TRUE, FALSE, or NA. This is a subjective judgement, but you should taking into account multiple factors, such as the presence/absence of decision errors, the number of target outcomes that could not be reproduced, the type of outcomes that could or could not be reproduced, the difference in magnitude of effect sizes, and the predictions of the specific hypothesis under scrutiny.
```


```{r}
reportObject <- reportObject %>%
  filter(dummyRow == FALSE) %>% # remove the dummy row
  select(-dummyRow) %>% # remove dummy row designation
  mutate(articleID = articleID) %>% # add variables to report 
  select(articleID, everything()) # make articleID first column

# decide on final outcome
if(any(reportObject$comparisonOutcome %in% c("MAJOR_ERROR", "DECISION_ERROR")) | Insufficient_Information_Errors > 0){
  finalOutcome <- "Failure without author assistance"
  if(Author_Assistance == T){
    finalOutcome <- "Failure despite author assistance"
  }
}else{
  finalOutcome <- "Success without author assistance"
  if(Author_Assistance == T){
    finalOutcome <- "Success with author assistance"
  }
}

# collate report extra details
reportExtras <- data.frame(articleID, pilotNames, copilotNames, pilotTTC, copilotTTC, pilotStartDate, copilotStartDate, completionDate, Author_Assistance, finalOutcome, Insufficient_Information_Errors, locus_typo, locus_specification, locus_analysis, locus_data, locus_unidentified, locus_typo_resolved, locus_specification_resolved, locus_analysis_resolved, locus_data_resolved, locus_unidentified_resolved)

# save report objects
if(reportType == "pilot"){
  write_csv(reportObject, "pilotReportDetailed.csv")
  write_csv(reportExtras, "pilotReportExtras.csv")
}

if(reportType == "final"){
  write_csv(reportObject, "finalReportDetailed.csv")
  write_csv(reportExtras, "finalReportExtras.csv")
}
```

# Session information

[This function will output information about the package versions used in this report:]

```{r session_info, include=TRUE, echo=TRUE, results='markup'}
devtools::session_info()
```
